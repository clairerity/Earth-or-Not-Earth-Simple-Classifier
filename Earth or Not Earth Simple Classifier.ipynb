{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earth or Non-Earth Simple Classification using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## DATA PROCESSING IMPORTS ######## \n",
    "\n",
    "# Dataset Pre-processing\n",
    "from skimage import color\n",
    "from sklearn import preprocessing # for normalization\n",
    "\n",
    "######## TRAINING IMPORTS ######## \n",
    "\n",
    "# Label (y) Processing\n",
    "from sklearn.preprocessing import LabelEncoder # Convert labels (y) from string to integer\n",
    "\n",
    "# Model \n",
    "from sklearn.model_selection import train_test_split # Split train and test data\n",
    "from sklearn.svm import SVC # SVM model\n",
    "from sklearn.metrics import classification_report # Scores the trained model using test set\n",
    "\n",
    "# Cross Validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "######## OTHER IMPORTS ######## \n",
    "\n",
    "# Math Functions and Plotting\n",
    "from numpy import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# General Library Imports\n",
    "import numpy as np # Math and array functions\n",
    "import cv2 # OpenCV\n",
    "import os # OS interactions\n",
    "import joblib # Lightweight save/load of large data (like models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Fetch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Positive Images:  198\n",
      "Number of Negative Images:  120\n"
     ]
    }
   ],
   "source": [
    "# True Images\n",
    "positive_path = r\"Positive images here\" \n",
    "# False Images\n",
    "negative_path = r\"Negative images here\"\n",
    "\n",
    "# os.listdir returns a list containing the names of the entries in the directory given by path.\n",
    "postivie_list = os.listdir(positive_path)\n",
    "negative_list = os.listdir(negative_path)\n",
    "\n",
    "# Total number of images in given path\n",
    "pos_total_data = size(postivie_list)\n",
    "neg_total_data = size(negative_list)\n",
    "print(\"Number of Positive Images: \", pos_total_data)\n",
    "print(\"Number of Negative Images: \", neg_total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Pre-process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pre-processing function\n",
    "def Preprocess_dataset(img):\n",
    "    img = cv2.resize(img,(320,140)) # Resize so all dataset will have a uniform size\n",
    "    gray = color.rgb2gray(img)  # Convert to grayscale\n",
    "    return gray\n",
    "\n",
    "# Vector for data and target\n",
    "features = [] #X (features of a certain image) aka data\n",
    "labels = [] #Y (label) aka target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-process done!\n"
     ]
    }
   ],
   "source": [
    "# Pre-process each file in dataset\n",
    "for file in postivie_list: \n",
    "    img = cv2.imread(os.path.join(positive_path,file)) # Open file using OpenCV and OS\n",
    "    gray = Preprocess_dataset(img)\n",
    "    features.append(gray)\n",
    "    labels.append(1) # Positive images are labeled as \"1\"\n",
    "    \n",
    "for file in negative_list: \n",
    "    img = cv2.imread(os.path.join(negative_path,file)) # Open file using OpenCV and OS\n",
    "    gray = Preprocess_dataset(img)\n",
    "    features.append(gray)\n",
    "    labels.append(0) # Negative images are labeled as \"0\"    \n",
    "    \n",
    "print('Pre-process done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Train the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting training and testing dataset...\n",
      "Training SVM Model...\n",
      "Training done!\n",
      "Evaluating the model using test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        18\n",
      "           1       1.00      0.93      0.97        46\n",
      "\n",
      "    accuracy                           0.95        64\n",
      "   macro avg       0.93      0.97      0.94        64\n",
      "weighted avg       0.96      0.95      0.95        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process the labels \n",
    "le = LabelEncoder() # Convert labels from string to integers\n",
    "labels = le.fit_transform(labels) #Scale training labels to standardized mean and variance\n",
    "\n",
    "# Split training and testing data (80%-Train ; 20%-Test)\n",
    "print(\"Splitting training and testing dataset...\")\n",
    "(trainFeatures, testFeatures, trainLabels, testLabels) = train_test_split(np.array(features), labels, test_size=0.20, random_state=2)\n",
    "\n",
    "# Adjust dimensions of train and test features\n",
    "nsamples, nx, ny = trainFeatures.shape\n",
    "trainFeatures = trainFeatures.reshape((nsamples,nx*ny))\n",
    "msamples, mx, my = testFeatures.shape\n",
    "testFeatures = testFeatures.reshape((msamples,mx*my))\n",
    "\n",
    "# Train the model\n",
    "print(\"Training SVM Model...\")\n",
    "model = SVC(kernel= 'rbf', C=10) # Use SVM model with a Radial Basis Function Kernel and Regularizer C (try 4)\n",
    "model.fit(trainFeatures, trainLabels) # Fit training data using SVM model\n",
    "print(\"Training done!\")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluating the model using test data ...\")\n",
    "predictedLabel = model.predict(testFeatures) # Evaluate model using test data (aka prediction)\n",
    "print(classification_report(testLabels, predictedLabel)) # Print test evaluation report (true label, predicted label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Cross Validate (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9646274509803922\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_val_score(model, trainFeatures, trainLabels, cv=5) # K-fold = 5\n",
    "print(cv_results.mean()) # Mean score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Earth or Not Earth Simple Classifier.npy']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model:\n",
    "joblib.dump(model, 'Earth or Not Earth Simple Classifier.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(r'Model path here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image...\n",
      "(1) Earth\n"
     ]
    }
   ],
   "source": [
    "img_orig = cv2.imread(\"image to test here\")\n",
    "print(\"Processing Image...\")\n",
    "gray = Preprocess_dataset(img_orig)\n",
    "#hog1 = feature_hog(gray)\n",
    "#hog2 = preprocessing.normalize([hog1])\n",
    "#hist = feature_lbp(gray)\n",
    "#hist2 = preprocessing.normalize([hist])\n",
    "#all_features = np.hstack([hog2, hist2]) \n",
    "window_feat = gray.reshape(1, -1)\n",
    "prediction = model.predict(window_feat)\n",
    "if prediction == 1:\n",
    "    print('(1) Earth')\n",
    "elif prediction == 0:\n",
    "    print('(0) Non-Earth')\n",
    "else:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
